{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4NyZJtkbied/6gbHODJdp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Najamzfr/ML-Zoomcamp-Project2/blob/main/MLzoomcamp_project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from scipy.optimize import minimize"
      ],
      "metadata": {
        "id": "Ud8y7r75UeDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create directory structure\n",
        "def create_directories():\n",
        "    directories = [\n",
        "        \"data/raw\",\n",
        "        \"data/processed\",\n",
        "        \"notebooks\",\n",
        "        \"src\",\n",
        "        \"models/saved_models\",\n",
        "        \"models/model_analysis\",\n",
        "        \"reports/figures\",\n",
        "        \"tests\",\n",
        "    ]\n",
        "    for directory in directories:\n",
        "        os.makedirs(directory, exist_ok=True)"
      ],
      "metadata": {
        "id": "4t1FaRWPUiKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Download stock data\n",
        "def download_stock_data(tickers, start_date, end_date):\n",
        "    raw_data_path = \"data/raw\"\n",
        "    for ticker in tickers:\n",
        "        print(f\"Downloading data for {ticker}...\")\n",
        "        stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
        "        file_path = os.path.join(raw_data_path, f\"{ticker}.csv\")\n",
        "        stock_data.to_csv(file_path)\n",
        "        print(f\"Saved {ticker} data to {file_path}\")"
      ],
      "metadata": {
        "id": "vA8WOCplUkO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"data/raw/AAPL.csv\")\n",
        "data = data.rename(columns={'Price': 'Date'})\n",
        "data = data.iloc[2:]\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "csGBRn1nVVws",
        "outputId": "65b3a8cd-c782-4939-d028-3fd952577031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Date               Close                High                 Low  \\\n",
              "2     2018-01-02  40.524349212646484   40.53376126592413  39.818595981979136   \n",
              "3     2018-01-03   40.51728439331055   41.06306851269611  40.453769198969376   \n",
              "4     2018-01-04  40.705482482910156   40.80899350294978   40.48199473854038   \n",
              "5     2018-01-05   41.16893768310547    41.2559794312343  40.710198809708736   \n",
              "6     2018-01-08  41.016029357910156    41.3124444417875   40.91722074030425   \n",
              "...          ...                 ...                 ...                 ...   \n",
              "1757  2024-12-23  255.27000427246094  255.64999389648438   253.4499969482422   \n",
              "1758  2024-12-24  258.20001220703125   258.2099914550781   255.2899932861328   \n",
              "1759  2024-12-26   259.0199890136719   260.1000061035156   257.6300048828125   \n",
              "1760  2024-12-27  255.58999633789062  258.70001220703125  253.05999755859375   \n",
              "1761  2024-12-30   252.1999969482422               253.5              250.75   \n",
              "\n",
              "                    Open     Volume  \n",
              "2      40.03032410496728  102223600  \n",
              "3     40.587860421113284  118071600  \n",
              "4      40.59020819429411   89738400  \n",
              "5      40.80194658438808   94640000  \n",
              "6     41.016029357910156   82271200  \n",
              "...                  ...        ...  \n",
              "1757  254.77000427246094   40858800  \n",
              "1758  255.49000549316406   23234700  \n",
              "1759  258.19000244140625   27237100  \n",
              "1760   257.8299865722656   42355300  \n",
              "1761  252.22999572753906   35557500  \n",
              "\n",
              "[1760 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f3690d7-4700-4d34-b874-6be4ac139b0d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Close</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-01-02</td>\n",
              "      <td>40.524349212646484</td>\n",
              "      <td>40.53376126592413</td>\n",
              "      <td>39.818595981979136</td>\n",
              "      <td>40.03032410496728</td>\n",
              "      <td>102223600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-01-03</td>\n",
              "      <td>40.51728439331055</td>\n",
              "      <td>41.06306851269611</td>\n",
              "      <td>40.453769198969376</td>\n",
              "      <td>40.587860421113284</td>\n",
              "      <td>118071600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-01-04</td>\n",
              "      <td>40.705482482910156</td>\n",
              "      <td>40.80899350294978</td>\n",
              "      <td>40.48199473854038</td>\n",
              "      <td>40.59020819429411</td>\n",
              "      <td>89738400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2018-01-05</td>\n",
              "      <td>41.16893768310547</td>\n",
              "      <td>41.2559794312343</td>\n",
              "      <td>40.710198809708736</td>\n",
              "      <td>40.80194658438808</td>\n",
              "      <td>94640000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2018-01-08</td>\n",
              "      <td>41.016029357910156</td>\n",
              "      <td>41.3124444417875</td>\n",
              "      <td>40.91722074030425</td>\n",
              "      <td>41.016029357910156</td>\n",
              "      <td>82271200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1757</th>\n",
              "      <td>2024-12-23</td>\n",
              "      <td>255.27000427246094</td>\n",
              "      <td>255.64999389648438</td>\n",
              "      <td>253.4499969482422</td>\n",
              "      <td>254.77000427246094</td>\n",
              "      <td>40858800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1758</th>\n",
              "      <td>2024-12-24</td>\n",
              "      <td>258.20001220703125</td>\n",
              "      <td>258.2099914550781</td>\n",
              "      <td>255.2899932861328</td>\n",
              "      <td>255.49000549316406</td>\n",
              "      <td>23234700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1759</th>\n",
              "      <td>2024-12-26</td>\n",
              "      <td>259.0199890136719</td>\n",
              "      <td>260.1000061035156</td>\n",
              "      <td>257.6300048828125</td>\n",
              "      <td>258.19000244140625</td>\n",
              "      <td>27237100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1760</th>\n",
              "      <td>2024-12-27</td>\n",
              "      <td>255.58999633789062</td>\n",
              "      <td>258.70001220703125</td>\n",
              "      <td>253.05999755859375</td>\n",
              "      <td>257.8299865722656</td>\n",
              "      <td>42355300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1761</th>\n",
              "      <td>2024-12-30</td>\n",
              "      <td>252.1999969482422</td>\n",
              "      <td>253.5</td>\n",
              "      <td>250.75</td>\n",
              "      <td>252.22999572753906</td>\n",
              "      <td>35557500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1760 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f3690d7-4700-4d34-b874-6be4ac139b0d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8f3690d7-4700-4d34-b874-6be4ac139b0d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8f3690d7-4700-4d34-b874-6be4ac139b0d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-748a85ea-36e9-4a56-8a82-af3b4132c695\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-748a85ea-36e9-4a56-8a82-af3b4132c695')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-748a85ea-36e9-4a56-8a82-af3b4132c695 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_37bf40e7-eead-4d05-aa56-85d289c67117\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_37bf40e7-eead-4d05-aa56-85d289c67117 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "repr_error": "0"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"data/raw/TSLA.csv\", header=2, parse_dates=[\"Date\"], index_col=\"Date\")\n",
        "# rename unnamed columns with these Close\tHigh\tLow\tOpen\tVolume\n",
        "df = df.rename(columns={'Unnamed: 1': 'Close','Unnamed: 2': 'High','Unnamed: 3': 'Low','Unnamed: 4': 'Open','Unnamed: 5': 'Volume'})\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "83lhsB2VvCak",
        "outputId": "3add405f-55ce-4473-aa3a-65ea63c7b0cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Close        High         Low        Open     Volume\n",
              "Date                                                                 \n",
              "2018-01-02   21.368668   21.474001   20.733334   20.799999   65283000\n",
              "2018-01-03   21.150000   21.683332   21.036667   21.400000   67822500\n",
              "2018-01-04   20.974667   21.236668   20.378668   20.858000  149194500\n",
              "2018-01-05   21.105333   21.149332   20.799999   21.108000   68868000\n",
              "2018-01-08   22.427334   22.468000   21.033333   21.066668  147891000\n",
              "...                ...         ...         ...         ...        ...\n",
              "2024-12-23  430.600006  434.510010  415.410004  431.000000   72698100\n",
              "2024-12-24  462.279999  462.779999  435.140015  435.899994   59551800\n",
              "2024-12-26  454.130005  465.329987  451.019989  465.160004   76366400\n",
              "2024-12-27  431.660004  450.000000  426.500000  449.519989   82666800\n",
              "2024-12-30  417.410004  427.000000  415.750000  419.399994   64941000\n",
              "\n",
              "[1760 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f990a8e-7814-4446-bf47-3a2a55f85cb1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2018-01-02</th>\n",
              "      <td>21.368668</td>\n",
              "      <td>21.474001</td>\n",
              "      <td>20.733334</td>\n",
              "      <td>20.799999</td>\n",
              "      <td>65283000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-03</th>\n",
              "      <td>21.150000</td>\n",
              "      <td>21.683332</td>\n",
              "      <td>21.036667</td>\n",
              "      <td>21.400000</td>\n",
              "      <td>67822500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-04</th>\n",
              "      <td>20.974667</td>\n",
              "      <td>21.236668</td>\n",
              "      <td>20.378668</td>\n",
              "      <td>20.858000</td>\n",
              "      <td>149194500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-05</th>\n",
              "      <td>21.105333</td>\n",
              "      <td>21.149332</td>\n",
              "      <td>20.799999</td>\n",
              "      <td>21.108000</td>\n",
              "      <td>68868000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-08</th>\n",
              "      <td>22.427334</td>\n",
              "      <td>22.468000</td>\n",
              "      <td>21.033333</td>\n",
              "      <td>21.066668</td>\n",
              "      <td>147891000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-12-23</th>\n",
              "      <td>430.600006</td>\n",
              "      <td>434.510010</td>\n",
              "      <td>415.410004</td>\n",
              "      <td>431.000000</td>\n",
              "      <td>72698100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-12-24</th>\n",
              "      <td>462.279999</td>\n",
              "      <td>462.779999</td>\n",
              "      <td>435.140015</td>\n",
              "      <td>435.899994</td>\n",
              "      <td>59551800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-12-26</th>\n",
              "      <td>454.130005</td>\n",
              "      <td>465.329987</td>\n",
              "      <td>451.019989</td>\n",
              "      <td>465.160004</td>\n",
              "      <td>76366400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-12-27</th>\n",
              "      <td>431.660004</td>\n",
              "      <td>450.000000</td>\n",
              "      <td>426.500000</td>\n",
              "      <td>449.519989</td>\n",
              "      <td>82666800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-12-30</th>\n",
              "      <td>417.410004</td>\n",
              "      <td>427.000000</td>\n",
              "      <td>415.750000</td>\n",
              "      <td>419.399994</td>\n",
              "      <td>64941000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1760 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f990a8e-7814-4446-bf47-3a2a55f85cb1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7f990a8e-7814-4446-bf47-3a2a55f85cb1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7f990a8e-7814-4446-bf47-3a2a55f85cb1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4b6d5a5a-16a6-4f3c-a502-96957215ab88\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4b6d5a5a-16a6-4f3c-a502-96957215ab88')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4b6d5a5a-16a6-4f3c-a502-96957215ab88 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6f990dec-274c-4df8-a8fb-579f91f429a3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6f990dec-274c-4df8-a8fb-579f91f429a3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1760,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2018-01-02 00:00:00\",\n        \"max\": \"2024-12-30 00:00:00\",\n        \"num_unique_values\": 1760,\n        \"samples\": [\n          \"2022-06-22 00:00:00\",\n          \"2022-02-03 00:00:00\",\n          \"2024-09-11 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 112.31201088746734,\n        \"min\": 11.9313325881958,\n        \"max\": 479.8599853515625,\n        \"num_unique_values\": 1736,\n        \"samples\": [\n          259.4599914550781,\n          238.8300018310547,\n          222.17999267578125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 114.90068882898323,\n        \"min\": 12.445332527160645,\n        \"max\": 488.5400085449219,\n        \"num_unique_values\": 1706,\n        \"samples\": [\n          53.55733489990234,\n          221.2899932861328,\n          226.3999938964844\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 109.63501221314448,\n        \"min\": 11.79933261871338,\n        \"max\": 457.510009765625,\n        \"num_unique_values\": 1723,\n        \"samples\": [\n          19.14466667175293,\n          242.3999938964844,\n          33.46666717529297\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 112.39951697421512,\n        \"min\": 12.07333278656006,\n        \"max\": 475.8999938964844,\n        \"num_unique_values\": 1714,\n        \"samples\": [\n          218.88999938964844,\n          194.4199981689453,\n          27.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 79610217,\n        \"min\": 29401800,\n        \"max\": 914082000,\n        \"num_unique_values\": 1755,\n        \"samples\": [\n          150579000,\n          76477500,\n          72721500\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Data Preprocessing\n",
        "def preprocess_data():\n",
        "    raw_data_path = \"data/raw\"\n",
        "    processed_data_path = \"data/processed\"\n",
        "\n",
        "    for file in os.listdir(raw_data_path):\n",
        "        if file.endswith(\".csv\"):\n",
        "            print(f\"Processing {file}...\")\n",
        "            file_path = os.path.join(raw_data_path, file)\n",
        "            data = pd.read_csv(file_path, header=2, parse_dates=[\"Date\"], index_col=\"Date\")  # Start from row 3\n",
        "            data = df.rename(columns={'Unnamed: 1': 'Close',\n",
        "                                      'Unnamed: 2': 'High',\n",
        "                                      'Unnamed: 3': 'Low',\n",
        "                                      'Unnamed: 4': 'Open',\n",
        "                                      'Unnamed: 5': 'Volume'})\n",
        "\n",
        "            # Retain only relevant columns\n",
        "            data = data[[\"Close\"]]\n",
        "\n",
        "            # Remove NaN rows (if any)\n",
        "            data = data.dropna()\n",
        "\n",
        "            # Save the processed data\n",
        "            processed_file_path = os.path.join(processed_data_path, file)\n",
        "            data.to_csv(processed_file_path)\n",
        "            print(f\"Saved processed data to {processed_file_path}\")\n"
      ],
      "metadata": {
        "id": "u9liPCs0Um70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Feature Engineering\n",
        "def feature_engineering():\n",
        "    processed_data_path = \"data/processed\"\n",
        "    for file in os.listdir(processed_data_path):\n",
        "        if file.endswith(\".csv\"):\n",
        "            print(f\"Engineering features for {file}...\")\n",
        "            file_path = os.path.join(processed_data_path, file)\n",
        "            data = pd.read_csv(file_path, parse_dates=[\"Date\"], index_col=\"Date\")\n",
        "\n",
        "            # Generate lag features\n",
        "            data[\"Lag_1\"] = data[\"Close\"].shift(1)\n",
        "            data[\"Lag_2\"] = data[\"Close\"].shift(2)\n",
        "\n",
        "            # Calculate moving averages\n",
        "            data[\"MA_5\"] = data[\"Close\"].rolling(window=5).mean()\n",
        "            data[\"MA_10\"] = data[\"Close\"].rolling(window=10).mean()\n",
        "\n",
        "            # Drop rows with NaN values introduced by lagging/rolling\n",
        "            data = data.dropna()\n",
        "\n",
        "            # Save engineered data\n",
        "            feature_file_path = os.path.join(processed_data_path, f\"features_{file}\")\n",
        "            data.to_csv(feature_file_path)\n",
        "            print(f\"Saved feature-engineered data to {feature_file_path}\")"
      ],
      "metadata": {
        "id": "RJGLjtTFUvxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Model Training\n",
        "def train_models():\n",
        "    processed_data_path = \"data/processed\"\n",
        "    models_path = \"models/saved_models\"\n",
        "    analysis_path = \"models/model_analysis\"\n",
        "    figures_path = \"reports/figures\"\n",
        "\n",
        "    os.makedirs(models_path, exist_ok=True)\n",
        "    os.makedirs(analysis_path, exist_ok=True)\n",
        "    os.makedirs(figures_path, exist_ok=True)\n",
        "\n",
        "    predictions = {}\n",
        "\n",
        "    for file in os.listdir(processed_data_path):\n",
        "        if file.startswith(\"features_\") and file.endswith(\".csv\"):\n",
        "            print(f\"Training models for {file}...\")\n",
        "            file_path = os.path.join(processed_data_path, file)\n",
        "            data = pd.read_csv(file_path, parse_dates=[\"Date\"], index_col=\"Date\")\n",
        "\n",
        "            # Prepare data for Linear Regression\n",
        "            X = data[[\"Lag_1\", \"Lag_2\", \"MA_5\", \"MA_10\"]]\n",
        "            y = data[\"Close\"]\n",
        "\n",
        "            # Split into training and testing sets\n",
        "            train_size = int(len(data) * 0.8)\n",
        "            X_train, X_test = X[:train_size], X[train_size:]\n",
        "            y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "            # Linear Regression Model\n",
        "            lr_model = LinearRegression()\n",
        "            lr_model.fit(X_train, y_train)\n",
        "            lr_predictions = lr_model.predict(X_test)\n",
        "\n",
        "            # Save Linear Regression Model\n",
        "            lr_model_path = os.path.join(models_path, f\"linear_regression_{file}.pkl\")\n",
        "            with open(lr_model_path, \"wb\") as f:\n",
        "                pickle.dump(lr_model, f)\n",
        "            print(f\"Saved Linear Regression model to {lr_model_path}\")\n",
        "\n",
        "            # Evaluate Linear Regression Model\n",
        "            lr_mse = mean_squared_error(y_test, lr_predictions)\n",
        "            lr_rmse = np.sqrt(lr_mse)\n",
        "            print(f\"Linear Regression RMSE for {file}: {lr_rmse}\")\n",
        "\n",
        "            # Align predictions by index (dates)\n",
        "            predictions[file] = pd.Series(lr_predictions, index=y_test.index)\n",
        "\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "2dcJqX4DUxH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Portfolio Optimization\n",
        "def optimize_portfolio(predictions):\n",
        "    print(\"Optimizing portfolio...\")\n",
        "\n",
        "    # Combine all predicted returns into a DataFrame\n",
        "    pred_returns = pd.DataFrame(predictions)\n",
        "    mean_returns = pred_returns.mean()  # Expected returns\n",
        "    cov_matrix = pred_returns.cov()  # Covariance matrix\n",
        "\n",
        "    # Objective function: minimize negative Sharpe ratio\n",
        "    def neg_sharpe(weights):\n",
        "        portfolio_return = np.dot(weights, mean_returns)\n",
        "        portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
        "        sharpe_ratio = portfolio_return / portfolio_volatility\n",
        "        return -sharpe_ratio\n",
        "\n",
        "    # Constraints: weights sum to 1\n",
        "    constraints = ({\"type\": \"eq\", \"fun\": lambda x: np.sum(x) - 1})\n",
        "    # Bounds: weights between 0 and 1\n",
        "    bounds = tuple((0, 1) for _ in range(len(mean_returns)))\n",
        "\n",
        "    # Initial guess\n",
        "    initial_weights = [1 / len(mean_returns)] * len(mean_returns)\n",
        "\n",
        "    # Optimization\n",
        "    result = minimize(neg_sharpe, initial_weights, method=\"SLSQP\", bounds=bounds, constraints=constraints)\n",
        "\n",
        "    optimal_weights = result.x\n",
        "    print(\"Optimal portfolio weights:\", optimal_weights)\n",
        "\n",
        "    # Plot efficient frontier\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(pred_returns.std(), mean_returns, label=\"Individual Stocks\")\n",
        "    plt.scatter(np.sqrt(np.dot(optimal_weights.T, np.dot(cov_matrix, optimal_weights))),\n",
        "                np.dot(optimal_weights, mean_returns), c=\"red\", label=\"Optimal Portfolio\", marker=\"X\", s=100)\n",
        "    plt.title(\"Efficient Frontier\")\n",
        "    plt.xlabel(\"Risk (Standard Deviation)\")\n",
        "    plt.ylabel(\"Return\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.savefig(\"reports/figures/efficient_frontier.png\")\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "mPsB10fpU55r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Backtest Portfolio\n",
        "def backtest_portfolio(optimal_weights, pred_returns, historical_prices):\n",
        "    print(\"Backtesting the optimized portfolio...\")\n",
        "\n",
        "    # Combine historical returns using optimal weights\n",
        "    portfolio_returns = (pred_returns @ optimal_weights)\n",
        "    cumulative_returns = (1 + portfolio_returns).cumprod() - 1\n",
        "\n",
        "    # Performance metrics\n",
        "    annualized_return = portfolio_returns.mean() * 252  # Assuming 252 trading days\n",
        "    annualized_volatility = portfolio_returns.std() * np.sqrt(252)\n",
        "    sharpe_ratio = annualized_return / annualized_volatility\n",
        "\n",
        "    # Print performance metrics\n",
        "    print(f\"Annualized Return: {annualized_return:.2%}\")\n",
        "    print(f\"Annualized Volatility: {annualized_volatility:.2%}\")\n",
        "    print(f\"Sharpe Ratio: {sharpe_ratio:.2f}\")\n",
        "\n",
        "    # Plot cumulative returns\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(cumulative_returns, label=\"Optimized Portfolio\")\n",
        "    plt.title(\"Backtest: Portfolio Cumulative Returns\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"Cumulative Returns\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.savefig(\"reports/figures/portfolio_backtest.png\")\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "yQIaYAD9AzZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Sensitivity analysis\n",
        "def sensitivity_analysis(mean_returns, cov_matrix):\n",
        "    print(\"Performing sensitivity analysis...\")\n",
        "    risk_aversion_levels = [0.1, 0.5, 1, 2, 5]  # Example risk aversion values\n",
        "    results = []\n",
        "\n",
        "    for risk_aversion in risk_aversion_levels:\n",
        "        # Adjusted Sharpe ratio objective (accounting for risk aversion)\n",
        "        def neg_sharpe_adjusted(weights):\n",
        "            portfolio_return = np.dot(weights, mean_returns)\n",
        "            portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
        "            return -(portfolio_return - risk_aversion * portfolio_volatility)\n",
        "\n",
        "        # Optimization\n",
        "        result = minimize(neg_sharpe_adjusted, initial_weights, method=\"SLSQP\", bounds=bounds, constraints=constraints)\n",
        "        results.append((risk_aversion, result.x))\n",
        "\n",
        "    # Display results\n",
        "    for level, weights in results:\n",
        "        print(f\"Risk Aversion {level}: {weights}\")\n"
      ],
      "metadata": {
        "id": "FMj8Dp4aAhkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "\n",
        "# Step 1: Create directory structure\n",
        "def create_directories():\n",
        "    directories = [\n",
        "        \"data/raw\",\n",
        "        \"data/processed\",\n",
        "        \"notebooks\",\n",
        "        \"src\",\n",
        "        \"models/saved_models\",\n",
        "        \"models/model_analysis\",\n",
        "        \"reports/figures\",\n",
        "        \"tests\",\n",
        "    ]\n",
        "    for directory in directories:\n",
        "        os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# Step 2: Download stock data\n",
        "def download_stock_data(tickers, start_date, end_date):\n",
        "    raw_data_path = \"data/raw\"\n",
        "    for ticker in tickers:\n",
        "        print(f\"Downloading data for {ticker}...\")\n",
        "        stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
        "        file_path = os.path.join(raw_data_path, f\"{ticker}.csv\")\n",
        "        stock_data.to_csv(file_path)\n",
        "        print(f\"Saved {ticker} data to {file_path}\")\n",
        "\n",
        "# Step 3: Data Preprocessing\n",
        "def preprocess_data():\n",
        "    raw_data_path = \"data/raw\"\n",
        "    processed_data_path = \"data/processed\"\n",
        "\n",
        "    for file in os.listdir(raw_data_path):\n",
        "        if file.endswith(\".csv\"):\n",
        "            print(f\"Processing {file}...\")\n",
        "            file_path = os.path.join(raw_data_path, file)\n",
        "            data = pd.read_csv(file_path, header=2, parse_dates=[\"Date\"], index_col=\"Date\")\n",
        "            data = data.rename(columns={'Unnamed: 1': 'Close',\n",
        "                                        'Unnamed: 2': 'High',\n",
        "                                        'Unnamed: 3': 'Low',\n",
        "                                        'Unnamed: 4': 'Open',\n",
        "                                        'Unnamed: 5': 'Volume'})\n",
        "\n",
        "            # Retain only relevant columns\n",
        "            data = data[[\"Close\"]]\n",
        "\n",
        "            # Remove NaN rows (if any)\n",
        "            data = data.dropna()\n",
        "\n",
        "            # Save the processed data\n",
        "            processed_file_path = os.path.join(processed_data_path, file)\n",
        "            data.to_csv(processed_file_path)\n",
        "            print(f\"Saved processed data to {processed_file_path}\")\n",
        "\n",
        "\n",
        "# Step 4: Feature Engineering\n",
        "def feature_engineering():\n",
        "    processed_data_path = \"data/processed\"\n",
        "    for file in os.listdir(processed_data_path):\n",
        "        if file.endswith(\".csv\"):\n",
        "            print(f\"Engineering features for {file}...\")\n",
        "            file_path = os.path.join(processed_data_path, file)\n",
        "            data = pd.read_csv(file_path, parse_dates=[\"Date\"], index_col=\"Date\")\n",
        "\n",
        "            # Generate lag features\n",
        "            data[\"Lag_1\"] = data[\"Close\"].shift(1)\n",
        "            data[\"Lag_2\"] = data[\"Close\"].shift(2)\n",
        "\n",
        "            # Calculate moving averages\n",
        "            data[\"MA_5\"] = data[\"Close\"].rolling(window=5).mean()\n",
        "            data[\"MA_10\"] = data[\"Close\"].rolling(window=10).mean()\n",
        "\n",
        "            # Drop rows with NaN values introduced by lagging/rolling\n",
        "            data = data.dropna()\n",
        "\n",
        "            # Save engineered data\n",
        "            feature_file_path = os.path.join(processed_data_path, f\"features_{file}\")\n",
        "            data.to_csv(feature_file_path)\n",
        "            print(f\"Saved feature-engineered data to {feature_file_path}\")\n",
        "\n",
        "# Step 5: Model Training\n",
        "def train_models():\n",
        "    processed_data_path = \"data/processed\"\n",
        "    models_path = \"models/saved_models\"\n",
        "    analysis_path = \"models/model_analysis\"\n",
        "    figures_path = \"reports/figures\"\n",
        "\n",
        "    os.makedirs(models_path, exist_ok=True)\n",
        "    os.makedirs(analysis_path, exist_ok=True)\n",
        "    os.makedirs(figures_path, exist_ok=True)\n",
        "\n",
        "    predictions = {}\n",
        "\n",
        "    for file in os.listdir(processed_data_path):\n",
        "        if file.startswith(\"features_\") and file.endswith(\".csv\"):\n",
        "            print(f\"Training models for {file}...\")\n",
        "            file_path = os.path.join(processed_data_path, file)\n",
        "            data = pd.read_csv(file_path, parse_dates=[\"Date\"], index_col=\"Date\")\n",
        "\n",
        "            # Prepare data for Linear Regression\n",
        "            X = data[[\"Lag_1\", \"Lag_2\", \"MA_5\", \"MA_10\"]]\n",
        "            y = data[\"Close\"]\n",
        "\n",
        "            # Split into training and testing sets\n",
        "            train_size = int(len(data) * 0.8)\n",
        "            X_train, X_test = X[:train_size], X[train_size:]\n",
        "            y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "            # Linear Regression Model\n",
        "            lr_model = LinearRegression()\n",
        "            lr_model.fit(X_train, y_train)\n",
        "            lr_predictions = lr_model.predict(X_test)\n",
        "\n",
        "            # Save Linear Regression Model\n",
        "            lr_model_path = os.path.join(models_path, f\"linear_regression_{file}.pkl\")\n",
        "            with open(lr_model_path, \"wb\") as f:\n",
        "                pickle.dump(lr_model, f)\n",
        "            print(f\"Saved Linear Regression model to {lr_model_path}\")\n",
        "\n",
        "            # Evaluate Linear Regression Model\n",
        "            lr_mse = mean_squared_error(y_test, lr_predictions)\n",
        "            lr_rmse = np.sqrt(lr_mse)\n",
        "            print(f\"Linear Regression RMSE for {file}: {lr_rmse}\")\n",
        "\n",
        "            # Align predictions by index (dates)\n",
        "            predictions[file] = pd.Series(lr_predictions, index=y_test.index)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Step 6: Model Performance Evaluation\n",
        "def evaluate_model(y_test, predictions, model_name):\n",
        "    mse = mean_squared_error(y_test, predictions)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_test, predictions)\n",
        "    r2 = r2_score(y_test, predictions)\n",
        "\n",
        "    print(f\"--- {model_name} Evaluation ---\")\n",
        "    print(f\"MSE: {mse:.4f}\")\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "    print(f\"R²: {r2:.4f}\")\n",
        "\n",
        "    # Residual plot\n",
        "    residuals = y_test - predictions\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(y_test, residuals, alpha=0.5)\n",
        "    plt.axhline(0, color='red', linestyle='--')\n",
        "    plt.title(f\"{model_name} Residuals\")\n",
        "    plt.xlabel(\"Actual Values\")\n",
        "    plt.ylabel(\"Residuals\")\n",
        "    plt.grid()\n",
        "    plt.savefig(f\"reports/figures/{model_name}_residuals.png\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# Step 7: Portfolio Optimization\n",
        "def optimize_portfolio(predictions):\n",
        "    print(\"Optimizing portfolio...\")\n",
        "\n",
        "    # Combine all predicted returns into a DataFrame\n",
        "    pred_returns = pd.DataFrame(predictions)\n",
        "    mean_returns = pred_returns.mean()  # Expected returns\n",
        "    cov_matrix = pred_returns.cov()  # Covariance matrix\n",
        "\n",
        "    # Objective function: minimize negative Sharpe ratio\n",
        "    def neg_sharpe(weights):\n",
        "        portfolio_return = np.dot(weights, mean_returns)\n",
        "        portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
        "        sharpe_ratio = portfolio_return / portfolio_volatility\n",
        "        return -sharpe_ratio\n",
        "\n",
        "    # Constraints: weights sum to 1\n",
        "    constraints = ({\"type\": \"eq\", \"fun\": lambda x: np.sum(x) - 1})\n",
        "    # Bounds: weights between 0 and 1\n",
        "    bounds = tuple((0, 1) for _ in range(len(mean_returns)))\n",
        "\n",
        "    # Initial guess\n",
        "    initial_weights = [1 / len(mean_returns)] * len(mean_returns)\n",
        "\n",
        "    # Optimization\n",
        "    result = minimize(neg_sharpe, initial_weights, method=\"SLSQP\", bounds=bounds, constraints=constraints)\n",
        "\n",
        "    optimal_weights = result.x\n",
        "    print(\"Optimal portfolio weights:\", optimal_weights)\n",
        "\n",
        "    # Plot efficient frontier\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(pred_returns.std(), mean_returns, label=\"Individual Stocks\")\n",
        "    plt.scatter(np.sqrt(np.dot(optimal_weights.T, np.dot(cov_matrix, optimal_weights))),\n",
        "                np.dot(optimal_weights, mean_returns), c=\"red\", label=\"Optimal Portfolio\", marker=\"X\", s=100)\n",
        "    plt.title(\"Efficient Frontier\")\n",
        "    plt.xlabel(\"Risk (Standard Deviation)\")\n",
        "    plt.ylabel(\"Return\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.savefig(\"reports/figures/efficient_frontier.png\")\n",
        "    plt.close()\n",
        "\n",
        "# Step 8: Portfolio Performance Evaluation\n",
        "def evaluate_portfolio(portfolio_returns):\n",
        "    # Annualized metrics\n",
        "    annualized_return = portfolio_returns.mean() * 252  # 252 trading days\n",
        "    annualized_volatility = portfolio_returns.std() * np.sqrt(252)\n",
        "    sharpe_ratio = annualized_return / annualized_volatility\n",
        "    max_drawdown = (portfolio_returns.cummin() - portfolio_returns.cummax()).min()\n",
        "\n",
        "    print(\"Portfolio Evaluation:\")\n",
        "    print(f\"Annualized Return: {annualized_return:.2%}\")\n",
        "    print(f\"Annualized Volatility: {annualized_volatility:.2%}\")\n",
        "    print(f\"Sharpe Ratio: {sharpe_ratio:.2f}\")\n",
        "    print(f\"Maximum Drawdown: {max_drawdown:.2%}\")\n",
        "\n",
        "    # Plot cumulative returns\n",
        "    cumulative_returns = (1 + portfolio_returns).cumprod() - 1\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(cumulative_returns, label=\"Optimized Portfolio\")\n",
        "    plt.title(\"Portfolio Cumulative Returns\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"Cumulative Returns\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.savefig(\"reports/figures/portfolio_cumulative_returns.png\")\n",
        "    plt.close()\n",
        "\n",
        "# Step 9: Backtest Portfolio\n",
        "def backtest_portfolio(optimal_weights, pred_returns, historical_prices):\n",
        "    print(\"Backtesting the optimized portfolio...\")\n",
        "\n",
        "    # Combine historical returns using optimal weights\n",
        "    portfolio_returns = (pred_returns @ optimal_weights)\n",
        "    cumulative_returns = (1 + portfolio_returns).cumprod() - 1\n",
        "\n",
        "    # Performance metrics\n",
        "    annualized_return = portfolio_returns.mean() * 252  # Assuming 252 trading days\n",
        "    annualized_volatility = portfolio_returns.std() * np.sqrt(252)\n",
        "    sharpe_ratio = annualized_return / annualized_volatility\n",
        "\n",
        "    # Print performance metrics\n",
        "    print(f\"Annualized Return: {annualized_return:.2%}\")\n",
        "    print(f\"Annualized Volatility: {annualized_volatility:.2%}\")\n",
        "    print(f\"Sharpe Ratio: {sharpe_ratio:.2f}\")\n",
        "\n",
        "    # Plot cumulative returns\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(cumulative_returns, label=\"Optimized Portfolio\")\n",
        "    plt.title(\"Backtest: Portfolio Cumulative Returns\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"Cumulative Returns\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.savefig(\"reports/figures/portfolio_backtest.png\")\n",
        "    plt.close()\n",
        "\n",
        "# Step 10: Sensitivity analysis\n",
        "def sensitivity_analysis(mean_returns, cov_matrix):\n",
        "    print(\"Performing sensitivity analysis...\")\n",
        "    risk_aversion_levels = [0.1, 0.5, 1, 2, 5]  # Example risk aversion values\n",
        "    results = []\n",
        "\n",
        "    for risk_aversion in risk_aversion_levels:\n",
        "        # Adjusted Sharpe ratio objective (accounting for risk aversion)\n",
        "        def neg_sharpe_adjusted(weights):\n",
        "            portfolio_return = np.dot(weights, mean_returns)\n",
        "            portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
        "            return -(portfolio_return - risk_aversion * portfolio_volatility)\n",
        "\n",
        "        # Optimization\n",
        "        result = minimize(neg_sharpe_adjusted, initial_weights, method=\"SLSQP\", bounds=bounds, constraints=constraints)\n",
        "        results.append((risk_aversion, result.x))\n",
        "\n",
        "    # Display results\n",
        "    for level, weights in results:\n",
        "        print(f\"Risk Aversion {level}: {weights}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Step 1: Create necessary directories\n",
        "    print(\"Step 1: Creating directories...\")\n",
        "    create_directories()\n",
        "\n",
        "    # Step 2: Define stock tickers and date range\n",
        "    print(\"Step 2: Downloading stock data...\")\n",
        "    tickers = [\"AAPL\", \"MSFT\", \"TSLA\", \"GOOGL\", \"AMZN\"]  # Example stock symbols\n",
        "    start_date = \"2018-01-01\"\n",
        "    end_date = \"2024-12-31\"\n",
        "    download_stock_data(tickers, start_date, end_date)\n",
        "\n",
        "    # Step 3: Preprocess downloaded data\n",
        "    print(\"Step 3: Preprocessing data...\")\n",
        "    preprocess_data()\n",
        "\n",
        "    # Step 4: Perform feature engineering\n",
        "    print(\"Step 4: Engineering features...\")\n",
        "    feature_engineering()\n",
        "\n",
        "    # Step 5: Train models and generate predictions\n",
        "    print(\"Step 5: Training models...\")\n",
        "    predictions = train_models()\n",
        "\n",
        "    # Step 6: Optimize portfolio based on predictions\n",
        "    print(\"Step 6: Optimizing portfolio...\")\n",
        "    optimize_portfolio(predictions)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "EICu8Fa1RiFz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5be3fc4-2dfb-47bd-a33b-6d15a76e5ef1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Creating directories...\n",
            "Step 2: Downloading stock data...\n",
            "Downloading data for AAPL...\n",
            "Saved AAPL data to data/raw/AAPL.csv\n",
            "Downloading data for MSFT...\n",
            "Saved MSFT data to data/raw/MSFT.csv\n",
            "Downloading data for TSLA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved TSLA data to data/raw/TSLA.csv\n",
            "Downloading data for GOOGL...\n",
            "Saved GOOGL data to data/raw/GOOGL.csv\n",
            "Downloading data for AMZN...\n",
            "Saved AMZN data to data/raw/AMZN.csv\n",
            "Step 3: Preprocessing data...\n",
            "Processing AMZN.csv...\n",
            "Saved processed data to data/processed/AMZN.csv\n",
            "Processing MSFT.csv...\n",
            "Saved processed data to data/processed/MSFT.csv\n",
            "Processing AAPL.csv...\n",
            "Saved processed data to data/processed/AAPL.csv\n",
            "Processing GOOGL.csv...\n",
            "Saved processed data to data/processed/GOOGL.csv\n",
            "Processing TSLA.csv...\n",
            "Saved processed data to data/processed/TSLA.csv\n",
            "Step 4: Engineering features...\n",
            "Engineering features for features_features_features_MSFT.csv...\n",
            "Saved feature-engineered data to data/processed/features_features_features_features_MSFT.csv\n",
            "Engineering features for features_features_features_AAPL.csv...\n",
            "Saved feature-engineered data to data/processed/features_features_features_features_AAPL.csv\n",
            "Engineering features for features_features_features_TSLA.csv...\n",
            "Saved feature-engineered data to data/processed/features_features_features_features_TSLA.csv\n",
            "Engineering features for features_features_features_features_features_GOOGL.csv...\n",
            "Saved feature-engineered data to data/processed/features_features_features_features_features_features_GOOGL.csv\n",
            "Engineering features for features_features_GOOGL.csv...\n",
            "Saved feature-engineered data to data/processed/features_features_features_GOOGL.csv\n",
            "Engineering features for features_features_features_features_AMZN.csv...\n",
            "Saved feature-engineered data to data/processed/features_features_features_features_features_AMZN.csv\n",
            "Engineering features for AMZN.csv...\n",
            "Saved feature-engineered data to data/processed/features_AMZN.csv\n",
            "Engineering features for features_features_features_GOOGL.csv...\n",
            "Saved feature-engineered data to data/processed/features_features_features_features_GOOGL.csv\n",
            "Engineering features for features_GOOGL.csv...\n",
            "Saved feature-engineered data to data/processed/features_features_GOOGL.csv\n",
            "Engineering features for MSFT.csv...\n",
            "Saved feature-engineered data to data/processed/features_MSFT.csv\n",
            "Engineering features for features_features_features_features_features_TSLA.csv...\n",
            "Saved feature-engineered data to data/processed/features_features_features_features_features_features_TSLA.csv\n",
            "Engineering features for features_TSLA.csv...\n",
            "Saved feature-engineered data to data/processed/features_features_TSLA.csv\n",
            "Engineering features for AAPL.csv...\n",
            "Saved feature-engineered data to data/processed/features_AAPL.csv\n",
            "Engineering features for features_MSFT.csv...\n",
            "Saved feature-engineered data to data/processed/features_features_MSFT.csv\n",
            "Engineering features for features_AAPL.csv...\n",
            "Saved feature-engineered data to data/processed/features_features_AAPL.csv\n",
            "Engineering features for features_features_AMZN.csv...\n",
            "Saved feature-engineered data to data/processed/features_features_features_AMZN.csv\n",
            "Engineering features for features_features_features_features_GOOGL.csv...\n",
            "Saved feature-engineered data to data/processed/features_features_features_features_features_GOOGL.csv\n",
            "Engineering features for features_features_features_features_features_MSFT.csv...\n",
            "Saved feature-engineered data to data/processed/features_features_features_features_features_features_MSFT.csv\n",
            "Engineering features for features_features_TSLA.csv...\n",
            "Saved feature-engineered data to data/processed/features_features_features_TSLA.csv\n",
            "Engineering features for features_features_AAPL.csv...\n",
            "Saved feature-engineered data to data/processed/features_features_features_AAPL.csv\n",
            "Engineering features for features_features_features_features_features_AAPL.csv...\n",
            "Saved feature-engineered data to data/processed/features_features_features_features_features_features_AAPL.csv\n",
            "Engineering features for features_features_features_features_MSFT.csv...\n",
            "Saved feature-engineered data to data/processed/features_features_features_features_features_MSFT.csv\n",
            "Engineering features for features_AMZN.csv...\n",
            "Saved feature-engineered data to data/processed/features_features_AMZN.csv\n",
            "Engineering features for features_features_features_AMZN.csv...\n",
            "Saved feature-engineered data to data/processed/features_features_features_features_AMZN.csv\n",
            "Engineering features for GOOGL.csv...\n",
            "Saved feature-engineered data to data/processed/features_GOOGL.csv\n",
            "Engineering features for TSLA.csv...\n",
            "Saved feature-engineered data to data/processed/features_TSLA.csv\n",
            "Engineering features for features_features_MSFT.csv...\n",
            "Saved feature-engineered data to data/processed/features_features_features_MSFT.csv\n",
            "Engineering features for features_features_features_features_AAPL.csv...\n",
            "Saved feature-engineered data to data/processed/features_features_features_features_features_AAPL.csv\n",
            "Engineering features for features_features_features_features_TSLA.csv...\n",
            "Saved feature-engineered data to data/processed/features_features_features_features_features_TSLA.csv\n",
            "Engineering features for features_features_features_features_features_AMZN.csv...\n",
            "Saved feature-engineered data to data/processed/features_features_features_features_features_features_AMZN.csv\n",
            "Step 5: Training models...\n",
            "Training models for features_features_features_MSFT.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_features_features_MSFT.csv.pkl\n",
            "Linear Regression RMSE for features_features_features_MSFT.csv: 4.161599082268195\n",
            "Training models for features_features_features_AAPL.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_features_features_AAPL.csv.pkl\n",
            "Linear Regression RMSE for features_features_features_AAPL.csv: 2.3109998932513203\n",
            "Training models for features_features_features_TSLA.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_features_features_TSLA.csv.pkl\n",
            "Linear Regression RMSE for features_features_features_TSLA.csv: 7.840336429521442\n",
            "Training models for features_features_features_features_features_GOOGL.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_features_features_features_features_GOOGL.csv.pkl\n",
            "Linear Regression RMSE for features_features_features_features_features_GOOGL.csv: 2.285414864882731\n",
            "Training models for features_features_GOOGL.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_features_GOOGL.csv.pkl\n",
            "Linear Regression RMSE for features_features_GOOGL.csv: 2.2702005527285967\n",
            "Training models for features_features_features_features_AMZN.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_features_features_features_AMZN.csv.pkl\n",
            "Linear Regression RMSE for features_features_features_features_AMZN.csv: 2.5134813525018074\n",
            "Training models for features_features_features_features_features_features_AMZN.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_features_features_features_features_features_AMZN.csv.pkl\n",
            "Linear Regression RMSE for features_features_features_features_features_features_AMZN.csv: 2.5213735618301705\n",
            "Training models for features_features_features_features_features_features_GOOGL.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_features_features_features_features_features_GOOGL.csv.pkl\n",
            "Linear Regression RMSE for features_features_features_features_features_features_GOOGL.csv: 7.8560238681319206\n",
            "Training models for features_features_features_GOOGL.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_features_features_GOOGL.csv.pkl\n",
            "Linear Regression RMSE for features_features_features_GOOGL.csv: 2.2769740858713488\n",
            "Training models for features_GOOGL.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_GOOGL.csv.pkl\n",
            "Linear Regression RMSE for features_GOOGL.csv: 2.2641434440440413\n",
            "Training models for features_features_features_features_features_TSLA.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_features_features_features_features_TSLA.csv.pkl\n",
            "Linear Regression RMSE for features_features_features_features_features_TSLA.csv: 7.868184052608062\n",
            "Training models for features_features_features_features_features_features_TSLA.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_features_features_features_features_features_TSLA.csv.pkl\n",
            "Linear Regression RMSE for features_features_features_features_features_features_TSLA.csv: 7.8560238681319206\n",
            "Training models for features_TSLA.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_TSLA.csv.pkl\n",
            "Linear Regression RMSE for features_TSLA.csv: 7.804852505369582\n",
            "Training models for features_MSFT.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_MSFT.csv.pkl\n",
            "Linear Regression RMSE for features_MSFT.csv: 4.142105141332675\n",
            "Training models for features_AAPL.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_AAPL.csv.pkl\n",
            "Linear Regression RMSE for features_AAPL.csv: 2.3113868766666106\n",
            "Training models for features_features_AMZN.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_features_AMZN.csv.pkl\n",
            "Linear Regression RMSE for features_features_AMZN.csv: 2.507087712282643\n",
            "Training models for features_features_features_features_GOOGL.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_features_features_features_GOOGL.csv.pkl\n",
            "Linear Regression RMSE for features_features_features_features_GOOGL.csv: 2.2821420070850964\n",
            "Training models for features_features_features_features_features_MSFT.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_features_features_features_features_MSFT.csv.pkl\n",
            "Linear Regression RMSE for features_features_features_features_features_MSFT.csv: 4.182813216349449\n",
            "Training models for features_features_features_features_features_features_AAPL.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_features_features_features_features_features_AAPL.csv.pkl\n",
            "Linear Regression RMSE for features_features_features_features_features_features_AAPL.csv: 2.3247374547341444\n",
            "Training models for features_features_TSLA.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_features_TSLA.csv.pkl\n",
            "Linear Regression RMSE for features_features_TSLA.csv: 7.818858737727817\n",
            "Training models for features_features_AAPL.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_features_AAPL.csv.pkl\n",
            "Linear Regression RMSE for features_features_AAPL.csv: 2.312250918214075\n",
            "Training models for features_features_features_features_features_AAPL.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_features_features_features_features_AAPL.csv.pkl\n",
            "Linear Regression RMSE for features_features_features_features_features_AAPL.csv: 2.3212982191168177\n",
            "Training models for features_features_features_features_MSFT.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_features_features_features_MSFT.csv.pkl\n",
            "Linear Regression RMSE for features_features_features_features_MSFT.csv: 4.172302617227006\n",
            "Training models for features_AMZN.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_AMZN.csv.pkl\n",
            "Linear Regression RMSE for features_AMZN.csv: 2.501513020562661\n",
            "Training models for features_features_features_features_features_features_MSFT.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_features_features_features_features_features_MSFT.csv.pkl\n",
            "Linear Regression RMSE for features_features_features_features_features_features_MSFT.csv: 4.185966671632541\n",
            "Training models for features_features_features_AMZN.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_features_features_AMZN.csv.pkl\n",
            "Linear Regression RMSE for features_features_features_AMZN.csv: 2.510770401415883\n",
            "Training models for features_features_MSFT.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_features_MSFT.csv.pkl\n",
            "Linear Regression RMSE for features_features_MSFT.csv: 4.153656344770803\n",
            "Training models for features_features_features_features_AAPL.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_features_features_features_AAPL.csv.pkl\n",
            "Linear Regression RMSE for features_features_features_features_AAPL.csv: 2.317331078202602\n",
            "Training models for features_features_features_features_TSLA.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_features_features_features_TSLA.csv.pkl\n",
            "Linear Regression RMSE for features_features_features_features_TSLA.csv: 7.855711155874718\n",
            "Training models for features_features_features_features_features_AMZN.csv...\n",
            "Saved Linear Regression model to models/saved_models/linear_regression_features_features_features_features_features_AMZN.csv.pkl\n",
            "Linear Regression RMSE for features_features_features_features_features_AMZN.csv: 2.5181002016061025\n",
            "Step 6: Optimizing portfolio...\n",
            "Optimizing portfolio...\n",
            "Optimal portfolio weights: [0.00000000e+00 2.67549222e-15 0.00000000e+00 9.16092604e-15\n",
            " 9.77911162e-15 4.65852106e-14 4.75448973e-14 0.00000000e+00\n",
            " 1.19620401e-14 1.15873829e-14 0.00000000e+00 0.00000000e+00\n",
            " 1.71967373e-01 0.00000000e+00 2.10972354e-15 5.02423350e-14\n",
            " 1.19309164e-14 5.37643965e-15 2.46434177e-15 1.05881970e-14\n",
            " 2.45829057e-15 2.84577297e-15 0.00000000e+00 5.02000733e-14\n",
            " 8.28032627e-01 4.48176029e-14 0.00000000e+00 2.65938543e-15\n",
            " 0.00000000e+00 4.75078355e-14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r reports.zip reports/\n",
        "\n",
        "from google.colab import files\n",
        "files.download('reports.zip')\n"
      ],
      "metadata": {
        "id": "a_jTpWzzy4cg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "b5e6a29a-6287-4157-f32e-29f9b65914e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: reports/ (stored 0%)\n",
            "  adding: reports/figures/ (stored 0%)\n",
            "  adding: reports/figures/arima_predictions_features_AMZN.csv.png (deflated 6%)\n",
            "  adding: reports/figures/lr_predictions_features_AAPL.csv.png (deflated 6%)\n",
            "  adding: reports/figures/lr_predictions_features_features_AMZN.csv.png (deflated 6%)\n",
            "  adding: reports/figures/lr_predictions_features_features_features_GOOGL.csv.png (deflated 7%)\n",
            "  adding: reports/figures/arima_predictions_features_features_features_features_AMZN.csv.png (deflated 7%)\n",
            "  adding: reports/figures/arima_predictions_features_TSLA.csv.png (deflated 7%)\n",
            "  adding: reports/figures/arima_predictions_features_features_features_MSFT.csv.png (deflated 6%)\n",
            "  adding: reports/figures/arima_predictions_features_GOOGL.csv.png (deflated 5%)\n",
            "  adding: reports/figures/arima_predictions_features_features_features_features_TSLA.csv.png (deflated 7%)\n",
            "  adding: reports/figures/lr_predictions_features_features_features_TSLA.csv.png (deflated 7%)\n",
            "  adding: reports/figures/arima_predictions_features_features_features_TSLA.csv.png (deflated 7%)\n",
            "  adding: reports/figures/arima_predictions_features_features_AMZN.csv.png (deflated 6%)\n",
            "  adding: reports/figures/arima_predictions_features_features_features_AAPL.csv.png (deflated 6%)\n",
            "  adding: reports/figures/arima_predictions_features_features_GOOGL.csv.png (deflated 7%)\n",
            "  adding: reports/figures/lr_predictions_features_features_features_MSFT.csv.png (deflated 6%)\n",
            "  adding: reports/figures/lr_predictions_features_features_TSLA.csv.png (deflated 7%)\n",
            "  adding: reports/figures/lr_predictions_features_features_features_AMZN.csv.png (deflated 7%)\n",
            "  adding: reports/figures/arima_predictions_features_features_MSFT.csv.png (deflated 6%)\n",
            "  adding: reports/figures/arima_predictions_features_features_features_GOOGL.csv.png (deflated 7%)\n",
            "  adding: reports/figures/arima_predictions_features_features_features_features_MSFT.csv.png (deflated 7%)\n",
            "  adding: reports/figures/arima_predictions_features_features_features_features_AAPL.csv.png (deflated 7%)\n",
            "  adding: reports/figures/lr_predictions_features_MSFT.csv.png (deflated 6%)\n",
            "  adding: reports/figures/lr_predictions_features_features_MSFT.csv.png (deflated 6%)\n",
            "  adding: reports/figures/lr_predictions_features_features_features_features_GOOGL.csv.png (deflated 7%)\n",
            "  adding: reports/figures/lr_predictions_features_TSLA.csv.png (deflated 7%)\n",
            "  adding: reports/figures/lr_predictions_features_features_features_features_MSFT.csv.png (deflated 7%)\n",
            "  adding: reports/figures/arima_predictions_features_AAPL.csv.png (deflated 6%)\n",
            "  adding: reports/figures/lr_predictions_features_features_features_features_AMZN.csv.png (deflated 7%)\n",
            "  adding: reports/figures/lr_predictions_features_features_features_features_TSLA.csv.png (deflated 7%)\n",
            "  adding: reports/figures/arima_predictions_features_features_AAPL.csv.png (deflated 6%)\n",
            "  adding: reports/figures/arima_predictions_features_MSFT.csv.png (deflated 6%)\n",
            "  adding: reports/figures/arima_predictions_features_features_features_AMZN.csv.png (deflated 7%)\n",
            "  adding: reports/figures/arima_predictions_features_features_TSLA.csv.png (deflated 7%)\n",
            "  adding: reports/figures/lr_predictions_features_features_features_features_AAPL.csv.png (deflated 7%)\n",
            "  adding: reports/figures/lr_predictions_features_GOOGL.csv.png (deflated 5%)\n",
            "  adding: reports/figures/lr_predictions_features_features_AAPL.csv.png (deflated 6%)\n",
            "  adding: reports/figures/arima_predictions_features_features_features_features_GOOGL.csv.png (deflated 7%)\n",
            "  adding: reports/figures/lr_predictions_features_AMZN.csv.png (deflated 6%)\n",
            "  adding: reports/figures/efficient_frontier.png (deflated 22%)\n",
            "  adding: reports/figures/lr_predictions_features_features_GOOGL.csv.png (deflated 7%)\n",
            "  adding: reports/figures/lr_predictions_features_features_features_AAPL.csv.png (deflated 6%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fe7a8bbf-abb0-41d7-a26c-a7ca9ea31863\", \"reports.zip\", 2443969)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NoPtGIEcL9Xz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}